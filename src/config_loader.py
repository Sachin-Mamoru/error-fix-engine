"""Loads and validates error config files into ErrorEntry dataclasses.

Loads two files and merges them:
  config/errors.yaml           – hand-curated seed list
  config/discovered_errors.yaml – auto-generated by src/discover.py (grows forever)
"""
from __future__ import annotations

from pathlib import Path

import yaml

from src.logger import get_logger
from src.models import ErrorEntry

log = get_logger(__name__)


def _parse_entries(raw_errors: list[dict], source: str) -> list[ErrorEntry]:
    """Convert raw YAML dicts to ErrorEntry objects, skipping malformed rows."""
    entries: list[ErrorEntry] = []
    for i, item in enumerate(raw_errors):
        try:
            entry = ErrorEntry(
                tool=item["tool"],
                error_name=item["error_name"],
                description=item.get("description", ""),
                context=item.get("context", ""),
                tags=item.get("tags", []),
                related=item.get("related", []),
                error_code=item.get("error_code"),
            )
            entries.append(entry)
        except (KeyError, TypeError) as exc:
            log.warning(
                "Skipping malformed error entry",
                source=source,
                index=i,
                error=str(exc),
            )
    return entries


def load_errors(config_path: Path) -> list[ErrorEntry]:
    """Load and merge the seed config plus any auto-discovered topics.

    Files loaded (in order, duplicates removed by slug):
      1. config_path                          (hand-curated seed list)
      2. config_path.parent/discovered_errors.yaml  (auto-generated, grows forever)
    """
    if not config_path.exists():
        raise FileNotFoundError(f"Config not found: {config_path}")

    raw = yaml.safe_load(config_path.read_text(encoding="utf-8"))
    entries = _parse_entries(raw.get("errors", []), source=config_path.name)

    # Merge auto-discovered topics (may not exist yet on first run)
    discovered_path = config_path.parent / "discovered_errors.yaml"
    if discovered_path.exists():
        raw_d = yaml.safe_load(discovered_path.read_text(encoding="utf-8")) or {}
        discovered = _parse_entries(raw_d.get("errors", []), source="discovered_errors.yaml")
        # Deduplicate: seed list wins on slug collision
        known_slugs = {e.slug for e in entries}
        for e in discovered:
            if e.slug not in known_slugs:
                entries.append(e)
                known_slugs.add(e.slug)
        log.info(
            "Discovered topics merged",
            discovered_total=len(raw_d.get("errors", [])),
            new_unique=len(entries) - (len(entries) - len(discovered)),
        )

    log.info("Errors loaded (combined)", count=len(entries))
    return entries


def load_generated_index(index_path: Path) -> set[str]:
    """Return the set of slugs that have already been generated."""
    if not index_path.exists():
        return set()
    try:
        data = yaml.safe_load(index_path.read_text(encoding="utf-8")) or {}
        return set(data.get("generated_slugs", []))
    except Exception as exc:  # noqa: BLE001
        log.warning("Could not read generated index", path=str(index_path), error=str(exc))
        return set()


def save_generated_index(index_path: Path, slugs: set[str]) -> None:
    """Persist the set of generated slugs to disk."""
    index_path.parent.mkdir(parents=True, exist_ok=True)
    data = {"generated_slugs": sorted(slugs)}
    index_path.write_text(yaml.dump(data, default_flow_style=False), encoding="utf-8")
    log.debug("Generated index saved", path=str(index_path), count=len(slugs))
